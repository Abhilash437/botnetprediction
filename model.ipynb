{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import layers, losses, Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nbaiot(filename):\n",
    "    return np.loadtxt(\n",
    "        os.path.join(\"/nbaiot-dataset\", filename),\n",
    "        delimiter=\",\",\n",
    "        skiprows=1\n",
    "    )\n",
    "\n",
    "benign = load_nbaiot(\"1.benign.csv\")\n",
    "X_train = benign[:40000]\n",
    "X_test0 = benign[40000:]\n",
    "X_test1 = load_nbaiot(\"1.mirai.scan.csv\")\n",
    "X_test2 = load_nbaiot(\"1.mirai.ack.csv\")\n",
    "X_test3 = load_nbaiot(\"1.mirai.syn.csv\")\n",
    "X_test4 = load_nbaiot(\"1.mirai.udp.csv\")\n",
    "X_test5 = load_nbaiot(\"1.mirai.udpplain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test0.shape, X_test1.shape, X_test2.shape,\n",
    "      X_test3.shape, X_test4.shape, X_test5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Sequential([\n",
    "            layers.Dense(115, activation=\"relu\"),\n",
    "            layers.Dense(86, activation=\"relu\"),\n",
    "            layers.Dense(57, activation=\"relu\"),\n",
    "            layers.Dense(37, activation=\"relu\"),\n",
    "            layers.Dense(28, activation=\"relu\")\n",
    "        ])\n",
    "        self.decoder = Sequential([\n",
    "            layers.Dense(37, activation=\"relu\"),\n",
    "            layers.Dense(57, activation=\"relu\"),\n",
    "            layers.Dense(86, activation=\"relu\"),\n",
    "            layers.Dense(115, activation=\"sigmoid\")\n",
    "        ])\n",
    "    \n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x = scaler.fit_transform(X_train)\n",
    "\n",
    "ae = Autoencoder()\n",
    "ae.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
    "monitor = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=1e-9,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='auto'\n",
    ")\n",
    "ae.fit(\n",
    "    x=x,\n",
    "    y=x,\n",
    "    epochs=800,\n",
    "    validation_split=0.3,\n",
    "    shuffle=True,\n",
    "    callbacks=[monitor]\n",
    ")\n",
    "\n",
    "training_loss = losses.mse(x, ae(x))\n",
    "threshold = np.mean(training_loss)+np.std(training_loss)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, threshold=threshold, window_size=82):\n",
    "    x = scaler.transform(x)\n",
    "    predictions = losses.mse(x, ae(x)) > threshold\n",
    "    # Majority voting over `window_size` predictions\n",
    "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
    "                     for i in range(window_size, len(predictions)+1)])\n",
    "\n",
    "def print_stats(data, outcome):\n",
    "    print(f\"Shape of data: {data.shape}\")\n",
    "    print(f\"Detected anomalies: {np.mean(outcome)*100}%\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [X_test0, X_test1, X_test2, X_test3, X_test4, X_test5]\n",
    "\n",
    "for i, x in enumerate(test_data):\n",
    "    print(i)\n",
    "    outcome = predict(x)\n",
    "    print_stats(x, outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.save_weights('my_autoencoder_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
